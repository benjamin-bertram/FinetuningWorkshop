{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjamin-bertram/FinetuningWorkshop/blob/main/cagliostro-colab-ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats] \n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Cagliostro Colab UI**\n",
        "All-in-One, Customizable and Flexible Stable Diffusion for Google Colab.\n",
        "\n",
        "[Github][link-to-github] | [What's New?][README] | [Pocketbook Guide][MANUAL]\n",
        "\n",
        "<!-- [visitor-badge]: https://visitor-badge.glitch.me/badge?page_id=linaqruf.cag-webui -->\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Cagliostro%20Colab%20UI&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Cagliostro%20Colab%20UI\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf\n",
        "[link-to-github]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb\n",
        "[README]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/README.md#whats-new\n",
        "[MANUAL]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#cagliostro-colab-ui-user-manual\n",
        "\n"
      ],
      "metadata": {
        "id": "WgQr3s96015a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Cagliostro Colab UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#install-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "import json\n",
        "import fileinput\n",
        "import base64\n",
        "from google.colab import drive\n",
        "from datetime import timedelta\n",
        "from subprocess import getoutput\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root directory\n",
        "root_dir = \"/content\"\n",
        "repo_dir = os.path.join(root_dir, \"cagliostro-colab-ui\")\n",
        "tmp_dir = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir = os.path.join(root_dir, \"patches\")\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "fused_dir = os.path.join(root_dir, \"fused\")\n",
        "\n",
        "# repository directory\n",
        "outputs_dir = os.path.join(repo_dir, \"outputs\")\n",
        "models_dir = os.path.join(repo_dir, \"models/Stable-diffusion\")\n",
        "vaes_dir = os.path.join(repo_dir, \"models/VAE\")\n",
        "hypernetworks_dir = os.path.join(repo_dir, \"models/hypernetworks\")\n",
        "embeddings_dir = os.path.join(repo_dir, \"embeddings\")\n",
        "extensions_dir = os.path.join(repo_dir, \"extensions\")\n",
        "lora_dir = os.path.join(repo_dir, \"models/Lora\")\n",
        "control_dir = os.path.join(repo_dir, \"models/ControlNet\")\n",
        "esrgan_dir = os.path.join(repo_dir, \"models/ESRGAN\")\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for dir in [ \"root_dir\", \"fused_dir\", \"repo_dir\", \"tmp_dir\", \"outputs_dir\", \"models_dir\", \"vaes_dir\", \"hypernetworks_dir\", \"embeddings_dir\", \"extensions_dir\", \"lora_dir\", \"control_dir\", \"esrgan_dir\"]:\n",
        "        %store {dir}\n",
        "    del cap\n",
        "    \n",
        "# url or path\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "webui_style_path = os.path.join(repo_dir, \"style.css\")\n",
        "voldemort=base64.b64decode((\"'c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ=='\").encode('ascii')).decode('ascii')\n",
        "dpm_v2_url = \"https://gist.github.com/neggles/75eaacb3f49c209636be61fa96ca95ca/raw/f8c6382f0af65038149fd4258f8462697b698073/01-add-DPMPP-2M-V2.patch\"\n",
        "sdv2_patches = \"https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch\"\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive = False  # @param {type:'boolean'}\n",
        "output_to_drive = False  # @param {type:'boolean'}\n",
        "output_drive_folder = \"cagliostro-colab-ui/outputs\" #@param {type:'string'}\n",
        "\n",
        "# @markdown ### **Repo Config**\n",
        "repo_type = \"AUTOMATIC1111\" #@param [\"AUTOMATIC1111\", \"Anapnoe\"]\n",
        "update_webui = True  # @param {type:'boolean'}\n",
        "update_extensions = True  # @param {type:'boolean'}\n",
        "commit_hash = \"\"  # @param {type:'string'}\n",
        "dpm_v2_patch = False  # @param {type:'boolean'}\n",
        "# @markdown > It's not recommended to set params below to `True` if you have **Colab Pro** subscription.\n",
        "ram_alloc_patch = False  # @param {type:'boolean'}\n",
        "colab_optimizations = False  # @param {type:'boolean'}\n",
        "\n",
        "\n",
        "# model\n",
        "os.chdir(root_dir)\n",
        "\n",
        "package_url = [\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-deps.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "def ubuntu_deps(url, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    filename = os.path.basename(url)\n",
        "    !wget -q --show-progress {url}\n",
        "    with zipfile.ZipFile(filename, \"r\") as deps:\n",
        "        deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(filename)\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "def pre_download(desc, overwrite=False):\n",
        "    for package in tqdm(package_url, desc=desc):\n",
        "        with capture.capture_output() as cap:\n",
        "            package_name = os.path.basename(package)\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {package_name} {package}\n",
        "            if package_name == f\"{repo_type.lower()}-webui-deps.tar.lz4\":\n",
        "                !tar -xI lz4 -f {package_name} --overwrite-dir --directory=/usr/local/lib/python3.10/dist-packages/\n",
        "            else:\n",
        "                !tar -xI lz4 -f {package_name} {\"--overwrite-dir\" if overwrite else \"\"} --directory=/\n",
        "            os.remove(package_name)\n",
        "            del cap\n",
        "\n",
        "    if os.path.exists(\"/usr/local/lib/python3.10/dist-packages/ffmpy-0.3.0.dist-info\"):\n",
        "        shutil.rmtree(\"/usr/local/lib/python3.10/dist-packages/ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    s = getoutput(\"nvidia-smi\")\n",
        "    with capture.capture_output() as cap:\n",
        "        if not \"T4\" in s:\n",
        "            !pip uninstall -y xformers\n",
        "            !pip install -q xformers==0.0.18\n",
        "        del cap\n",
        "\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps_url = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ubuntu-deps.zip\"\n",
        "    ram_patch_url = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ram_patch.zip\"\n",
        "\n",
        "    print(\"\u001b[1;32mInstalling dependencies...\")\n",
        "    \n",
        "    with capture.capture_output() as cap:\n",
        "        !apt -y update -qq\n",
        "        !apt install unionfs-fuse -qq         \n",
        "        ubuntu_deps(ubuntu_deps_url, deps_dir)\n",
        "        if ram_alloc_patch:\n",
        "              !apt install libunwind8-dev -yqq \n",
        "              ubuntu_deps(ram_patch_url, deps_dir)\n",
        "              os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "        del cap   \n",
        "\n",
        "def install_webui(overwrite):\n",
        "    desc = \"\u001b[1;32mUnpacking Webui\"\n",
        "    print(f\"\u001b[1;32mUsing {repo_type} version...\")\n",
        "    pre_download(desc, overwrite)\n",
        "\n",
        "    for dir in [patches_dir, fused_dir, models_dir, vaes_dir, hypernetworks_dir, embeddings_dir, extensions_dir, lora_dir, control_dir, esrgan_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def reinstall_webui():\n",
        "    os.chdir(repo_dir)\n",
        "    try:\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote -v\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "\n",
        "    output = cap.stdout.strip()\n",
        "    os.chdir(root_dir)\n",
        "    try:\n",
        "        if repo_type == \"Anapnoe\":\n",
        "          if f\"https://github.com/anapnoe/{voldemort}-ux\" in output:\n",
        "              print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "          else:\n",
        "            print(\"\u001b[1;32mReinstall Web UI, use Anapnoe version...\")\n",
        "            install_webui(overwrite=True)\n",
        "        elif repo_type == \"Automatic1111\":\n",
        "          if f\"https://github.com/AUTOMATIC1111/{voldemort}\" in output:\n",
        "              print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "          else:\n",
        "            print(\"\u001b[1;32mReinstall Web UI, use Automatic1111 version...\")\n",
        "            install_webui(overwrite=True)\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "            \n",
        "def main():\n",
        "    global drive_dir\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "            print(\"\u001b[1;32mMounting google drive...\")\n",
        "            drive.mount(\"/content/drive\")\n",
        "          \n",
        "    install_dependencies()\n",
        "\n",
        "    if not os.path.exists(repo_dir):\n",
        "        install_webui(overwrite=False)\n",
        "    else:\n",
        "        reinstall_webui()\n",
        "\n",
        "    if commit_hash:\n",
        "        try:\n",
        "            os.chdir(repo_dir)\n",
        "            with capture.capture_output() as cap:\n",
        "                !git reset --hard {commit_hash}\n",
        "                del cap\n",
        "            print(\"\u001b[1;32mCommit hash: \", commit_hash)\n",
        "        except Exception as e:\n",
        "            print(\"\u001b[1;32mAn error occurred while resetting the commit hash:\", e)\n",
        "\n",
        "    if update_webui:\n",
        "        try:\n",
        "            print(\"\u001b[1;32mUpdating Web UI to the latest version\")\n",
        "            with capture.capture_output() as cap:\n",
        "                os.chdir(repo_dir)\n",
        "                !git pull -X theirs --rebase --autostash\n",
        "            del cap\n",
        "        except Exception as e:\n",
        "            print(\"\u001b[1;32mAn error occurred when updating Web UI:\", e)\n",
        "\n",
        "    if dpm_v2_patch:\n",
        "        with capture.capture_output() as cap:\n",
        "            !wget {dpm_v2_url} -P {patches_dir}  -c\n",
        "            os.chdir(repo_dir)\n",
        "            !git apply --whitespace=fix {patches_dir}/01-add-DPMPP-2M-V2.patch\n",
        "\n",
        "    if colab_optimizations:\n",
        "        !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" {repo_dir}/modules/sd_models.py\n",
        "        !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' {repo_dir}/webui.py\n",
        "        !sed -i \"s@map_location='cpu'@map_location='cuda'@\" {repo_dir}/modules/extras.py\n",
        "        shutil.rmtree(patches_dir)\n",
        "\n",
        "    if output_to_drive: \n",
        "        if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "            print(\"\u001b[1;32mMounting google drive...\")\n",
        "            drive.mount(\"/content/drive\")\n",
        "        drive_dir = os.path.join(\"/content/drive/MyDrive\", output_drive_folder)\n",
        "        print(\"\u001b[1;32mSet default output path to:\", drive_dir)\n",
        "    else:\n",
        "        drive_dir = outputs_dir\n",
        "    \n",
        "    os.makedirs(drive_dir, exist_ok=True)\n",
        "    with capture.capture_output() as cap:\n",
        "        %store drive_dir\n",
        "        del cap\n",
        "\n",
        "    config = read_config(config_file)\n",
        "    config[\"outdir_txt2img_samples\"] = os.path.join(drive_dir, \"txt2img-images\")\n",
        "    config[\"outdir_img2img_samples\"] = os.path.join(drive_dir, \"img2img-images\")\n",
        "    config[\"outdir_extras_samples\"] = os.path.join(drive_dir, \"extras-images\")\n",
        "    config[\"outdir_txt2img_grids\"] = os.path.join(drive_dir, \"txt2img-grids\")\n",
        "    config[\"outdir_img2img_grids\"] = os.path.join(drive_dir, \"img2img-grids\")\n",
        "    write_config(config_file, config)\n",
        "\n",
        "    for dir in [\"txt2img-images\", \"img2img-images\", \"extras-images\", \"txt2img-grids\", \"img2img-grids\",]:\n",
        "        os.makedirs(os.path.join(drive_dir, dir), exist_ok=True)\n",
        "\n",
        "    skipped_extensions = []\n",
        "    \n",
        "    end_time = time.time()\n",
        "    elapsed_time = int(end_time - start_time)\n",
        "\n",
        "    if elapsed_time < 60:\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {elapsed_time} sec\")\n",
        "    else:\n",
        "        mins, secs = divmod(elapsed_time, 60)\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {mins} mins {secs} sec\")\n",
        "\n",
        "    if update_extensions:\n",
        "        start_time = time.time()\n",
        "        extensions_updated = []\n",
        "        extensions_list = os.listdir(extensions_dir)\n",
        "        with tqdm(\n",
        "            total=len(extensions_list) - len(skipped_extensions) - 1,\n",
        "            desc=\"\u001b[1;32mUpdating extensions\",\n",
        "            mininterval=0,\n",
        "        ) as pbar:\n",
        "            for dir in os.listdir(extensions_dir):\n",
        "                if os.path.isdir(os.path.join(extensions_dir, dir)):\n",
        "                    os.chdir(os.path.join(extensions_dir, dir))\n",
        "                    if dir not in skipped_extensions:\n",
        "                        try:\n",
        "                            with capture.capture_output() as cap:\n",
        "                                !git fetch origin\n",
        "                                !git pull\n",
        "                        except Exception as e:\n",
        "                            print(f\"\u001b[1;32mAn error occurred while updating {dir}: {e}\")\n",
        "                            \n",
        "                        output = cap.stdout.strip()\n",
        "                        if \"Already up to date.\" not in output:\n",
        "                            extensions_updated.append(dir)\n",
        "                        pbar.update(1)\n",
        "\n",
        "        for ext in extensions_updated:\n",
        "            print(f\"\u001b[1;32m- {ext} updated to new version\")\n",
        "        for ext in skipped_extensions:\n",
        "            print(f\"\u001b[1;32m- {ext} skipped\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = int(end_time - start_time)\n",
        "\n",
        "        if elapsed_time < 60:\n",
        "            print(f\"\u001b[1;32mAll extensions are up to date. Took {elapsed_time} sec\")\n",
        "        else:\n",
        "            mins, secs = divmod(elapsed_time, 60)\n",
        "            print(f\"\u001b[1;32mAll extensions are up to date. Took {mins} mins {secs} sec\")\n",
        "            \n",
        "    os.environ[\"colab_url\"] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "    print(\"\u001b[1;32mAll is done! Go to the next step.\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "A6c7-qjDdb0X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Model and VAE** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-model-and-vae)</small></small>\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown ### **SD v1.x Model**\n",
        "stable_diffusion1_5 = True  # @param {type: 'boolean'}\n",
        "anything_v3_0 = False  # @param {type: 'boolean'}\n",
        "anime_pastel_dream = False  # @param {type: 'boolean'}\n",
        "anylora = False  # @param {type: 'boolean'}\n",
        "chilloutmix_ni = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SD v2.x 768v Model**\n",
        "replicant_v2 = False  # @param {type: 'boolean'}\n",
        "waifu_diffusion_v1_5_e2_aesthetic = False  # @param {type: 'boolean'}\n",
        "illuminati_diffusion_v1_1 = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **VAE Model**\n",
        "anime = False  # @param {type: 'boolean'}\n",
        "waifu_diffusion = False  # @param {type: 'boolean'}\n",
        "stable_diffusion = True  # @param {type: 'boolean'}\n",
        "\n",
        "downloadModels = []\n",
        "downloadVAE = []\n",
        "\n",
        "models = [\n",
        "    (\"stable_diffusion1_5\", \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors\"),\n",
        "    (\"anything_v3_0\", \"https://huggingface.co/AdamOswald1/Anything-Preservation/resolve/4121e81acc47bb87e46480ba1344b5ab57134b88/Anything-V3.0-pruned.safetensors\"),\n",
        "    (\"anime_pastel_dream\", \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\"),\n",
        "    (\"anylora\", \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\"),\n",
        "    (\"chilloutmix_ni\", \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\"),\n",
        "    (\"replicant_v2\", \"https://huggingface.co/gsdf/Replicant-V2.0/resolve/main/Replicant-V2.0_fp16.safetensors\"),\n",
        "    (\"waifu_diffusion_v1_5_e2_aesthetic\", \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp16.safetensors\"),\n",
        "    (\"illuminati_diffusion_v1_1\", \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/illuminatiDiffusionV1_v11.safetensors\"),\n",
        "]\n",
        "\n",
        "vaeList = [\n",
        "    (\"anime\", \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\"),\n",
        "    (\"waifu_diffusion\", \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\"),\n",
        "    (\"stable_diffusion\", \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"),\n",
        "]\n",
        "\n",
        "for model, url in models:\n",
        "    if locals()[model]:  # if checkbox is checked\n",
        "        downloadModels.append((model, url))\n",
        "\n",
        "for vae, url in vaeList:\n",
        "    if locals()[vae]:  # if checkbox is checked\n",
        "        downloadVAE.append((vae, url))\n",
        "\n",
        "def download(checkpoint_name, url, is_vae=None, is_control=None):\n",
        "    basename = os.path.basename(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    if is_vae:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vaes_dir} -o {checkpoint_name}.vae.pt {url}\n",
        "    else:\n",
        "        if url.startswith(\"https://huggingface.co/\"):\n",
        "            ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "            !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {models_dir} -o {checkpoint_name}.{ext} {url}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {models_dir} {url}\n",
        "\n",
        "def main():\n",
        "    downloaded_model = []\n",
        "    downloaded_vae = []\n",
        "\n",
        "    for model in tqdm(downloadModels, desc=\"\u001b[1;32mDownloading Models\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(model[0], model[1], is_vae=False)\n",
        "            downloaded_model.append(model[0])\n",
        "            del cap\n",
        "\n",
        "    for vae in tqdm(downloadVAE, desc=\"\u001b[1;32mDownloading VAE\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(vae[0], vae[1], is_vae=True)\n",
        "            downloaded_vae.append(vae[0])\n",
        "            del cap\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")\n"
      ],
      "metadata": {
        "id": "qgvihy5BQ3II",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet v1.1** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#controlnet-v11)</small></small>\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import yaml\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, unquote\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "# @markdown ### **ControlNet Annotator**\n",
        "pre_download_annotator = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv1.x ControlNet Model**\n",
        "control_v11_sd15_model = False  # @param {type: 'boolean'}\n",
        "t2i_adapter_sd15_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv2.x ControlNet Model**\n",
        "control_v10_sd21_model = False  # @param {type: 'boolean'}\n",
        "control_v10_wd15_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **ControlNet Config**\n",
        "control_net_max_models_num = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "control_net_model_adapter_config = \"sketch_adapter_v14.yaml\" #@param [\"image_adapter_v14.yaml\", \"sketch_adapter_v14.yaml\", \"t2iadapter_color_sd14v1.yaml\", \"t2iadapter_keypose_sd14v1.yaml\", \"t2iadapter_style_sd14v1.yaml\"]\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "annotator_dict = {\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/150_16_swin_l_oneformer_coco_100ep.pth\",\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/250_16_swin_l_oneformer_ade20k_160k.pth\",\n",
        "    \"zoedepth\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/ZoeD_M12_N.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_beit_large_512.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_large-midas-2f21e586.pt\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/facenet.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hand_pose_model.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/body_pose_model.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/latest_net_G.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/res101.pth\",\n",
        "    \"mlsd\"          : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/mlsd_large_512_fp32.pth\",\n",
        "    \"lineart_anime\" : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/netG.pth\",\n",
        "    \"hed\"           : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/network-bsds500.pth\",\n",
        "    \"normal_bae\"    : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/scannet.pt\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model.pth\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model2.pth\",\n",
        "    \"pidinet\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/table5_pidinet.pth\",\n",
        "    \"uniformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/upernet_global_small.pth\",\n",
        "}\n",
        "\n",
        "control_v11_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "t2i_adapter_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_style_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_seg_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_openpose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_keypose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_color_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_zoedepth_sd15v1.pth\",\n",
        "]\n",
        "\n",
        "control_v10_sd21_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/canny-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/depth-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/hed-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/openpose-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/scribble-sd21-safe.safetensors\",\n",
        "]\n",
        "\n",
        "control_v10_wd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_canny.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_depth.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_pose.safetensors\",\n",
        "]\n",
        "\n",
        "def read_config(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def cldm_config_path(destination_path):\n",
        "    if \"_sd15_\" in destination_path or \"_sd15s2_\" in destination_path:\n",
        "        return \"cldm_v15.yaml\"\n",
        "    elif \"-sd21-\" in destination_path or \"_wd15beta2_\" in destination_path: \n",
        "        return \"cldm_v21.yaml\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def cldm_config(destination_path):\n",
        "    control_net_model_config = cldm_config_path(destination_path)\n",
        "    if control_net_model_config is not None:\n",
        "        cldm_config_src = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_config))\n",
        "        cldm_config_dst = os.path.splitext(destination_path)[0] + \".yaml\"\n",
        "        if \"_shuffle_\" in cldm_config_dst:\n",
        "            cldm_config_src = os.path.join(extensions_dir, \"sd-webui-controlnet/models/control_v11e_sd15_shuffle.yaml\")\n",
        "        if not os.path.exists(cldm_config_dst):\n",
        "            shutil.copy(cldm_config_src, cldm_config_dst)\n",
        "\n",
        "def download(url, destination_path, is_annotator=None):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    basename = os.path.basename(url)\n",
        "    dst_dir = os.path.join(os.path.dirname(control_dir), destination_path) if is_annotator else destination_path\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "    cldm_config(os.path.join(dst_dir, basename))\n",
        "\n",
        "def batch(url, download_description, is_annotator=None):\n",
        "    if is_annotator:\n",
        "        for dest_path, url in tqdm(annotator_dict.items(), desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(url, dest_path, is_annotator=True)\n",
        "                del cap\n",
        "    else:\n",
        "        for control in tqdm(url, desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(control, control_dir, is_annotator=False)\n",
        "                del cap\n",
        "\n",
        "def main():\n",
        "    config = read_config(config_file)\n",
        "    config[\"control_net_max_models_num\"] = control_net_max_models_num\n",
        "    config[\"control_net_models_path\"] = control_dir\n",
        "    config[\"control_net_model_adapter_config\"] = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_adapter_config))\n",
        "    config[\"control_net_allow_script_control\"] = True\n",
        "    write_config(config_file, config)\n",
        "  \n",
        "    if pre_download_annotator:\n",
        "        batch(annotator_dict, \n",
        "              \"ControlNet Annotator/Preprocessor\", \n",
        "              is_annotator=True)\n",
        "              \n",
        "    if control_v11_sd15_model:\n",
        "        batch(control_v11_sd15_url, \n",
        "              \"SDv1.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "    if t2i_adapter_sd15_model:\n",
        "        batch(t2i_adapter_sd15_url, \n",
        "              \"SDv1.x Text2Image Adapter Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if control_v10_sd21_model:\n",
        "        batch(control_v10_sd21_url, \n",
        "              \"SDv2.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if control_v10_wd15_model:\n",
        "        batch(control_v10_wd15_url, \n",
        "              \"WD1.5 ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LKKtxDoIIg1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Custom Download Corner** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#custom-download-corner)</small></small>\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import glob\n",
        "import requests\n",
        "import gc\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "from urllib.parse import urlparse, unquote\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "from safetensors.torch import load_file, save_file\n",
        "from torch import load, save\n",
        "import pickle as python_pickle\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown Fill in the URL fields with the links to the files you want to download. Separate multiple URLs with a comma.\n",
        "# @markdown Example: `url1, url2, url3`\n",
        "os.chdir(root_dir)\n",
        "\n",
        "custom_model_url = \"https://civitai.com/api/download/models/29460, https://civitai.com/api/download/models/9451?type=Model&format=SafeTensor, https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt, https://huggingface.co/timbrooks/instruct-pix2pix/blob/main/instruct-pix2pix-00-22000.safetensors, https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\"  # @param {'type': 'string'}\n",
        "custom_vae_url = \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"  # @param {'type': 'string'}\n",
        "custom_embedding_url = \"https://civitai.com/api/download/models/9603, https://civitai.com/api/download/models/10080, https://civitai.com/api/download/models/5469\"  # @param {'type': 'string'}\n",
        "custom_LoRA_url = \"https://civitai.com/api/download/models/21809, https://civitai.com/api/download/models/17765, https://civitai.com/api/download/models/30371\"  # @param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\"  # @param {'type': 'string'}\n",
        "custom_extensions_url = \"\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\"       : models_dir,\n",
        "    \"vae\"         : vaes_dir,\n",
        "    \"embedding\"   : embeddings_dir,\n",
        "    \"LoRA\"        : lora_dir,\n",
        "    \"hypernetwork\": hypernetworks_dir,\n",
        "    \"extensions\"  : extensions_dir,\n",
        "    \"upscaler\"    : esrgan_dir,    \n",
        "}\n",
        "\n",
        "def is_safetensors(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.safetensors'\n",
        "\n",
        "def extract(url, dst):\n",
        "    if not url.startswith(\"/content/\"):\n",
        "        filename = os.path.basename(url)\n",
        "        zipfile = os.path.join(dst, filename)\n",
        "    else:\n",
        "        zipfile = url\n",
        "\n",
        "    if url.endswith(\".zip\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !unzip -j -o {zipfile} -d \"{dst}\"\n",
        "            os.remove(zipfile)\n",
        "    elif url.endswith(\".tar.lz4\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !tar -xI lz4 -f {zipfile} --directory={dst}\n",
        "            os.remove(zipfile)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def unionfuse(folder_path, dst_dir):\n",
        "    try:\n",
        "        if \"extensions\" in category:\n",
        "            print(f\"\\n\u001b[1;32m{category.capitalize()} folder can't be fused, skipping...\")\n",
        "        else: \n",
        "            category_dir = os.path.join(os.path.join(root_dir,\"fused\"), category)\n",
        "            for dir in [folder_path, category_dir, dst_dir]:\n",
        "                os.makedirs(dir, exist_ok=True)\n",
        "            with capture.capture_output() as cap:    \n",
        "                !unionfs-fuse {dst_dir}=RW:\"{folder_path}\"=RW {category_dir}\n",
        "            output = cap.stdout.strip()\n",
        "            if \"fuse: mountpoint is not empty\" in output:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder is not empty and can't be fused, skipping...\")\n",
        "            else:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder fused successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u001b[1;32mAn error occurred while fusing the folders: {e}\")\n",
        "\n",
        "def prune_model(checkpoint, fp16=False, ema=False, clip=True, vae=True, depth=True, unet=True):\n",
        "    # Borrowed Lopho's code hehe\n",
        "    sd = checkpoint\n",
        "    nested_sd = False\n",
        "    if 'state_dict' in sd:\n",
        "        sd = sd['state_dict']\n",
        "        nested_sd = True\n",
        "    sd_pruned = dict()\n",
        "    for k in sd:\n",
        "        cp = unet and k.startswith('model.diffusion_model.')\n",
        "        cp = cp or (depth and k.startswith('depth_model.'))\n",
        "        cp = cp or (vae and k.startswith('first_stage_model.'))\n",
        "        cp = cp or (clip and k.startswith('cond_stage_model.'))\n",
        "        if cp:\n",
        "            k_in = k\n",
        "            if ema:\n",
        "                k_ema = 'model_ema.' + k[6:].replace('.', '')\n",
        "                if k_ema in sd:\n",
        "                    k_in = k_ema\n",
        "            sd_pruned[k] = sd[k_in].half() if fp16 else sd[k_in]\n",
        "    del sd\n",
        "\n",
        "    if nested_sd:\n",
        "        return {'state_dict': sd_pruned}\n",
        "    else:\n",
        "        return sd_pruned\n",
        "\n",
        "def autoprune(model_path, prefix):\n",
        "    def bytes_to_gb(size_in_bytes):\n",
        "        return size_in_bytes / (1024 * 1024 * 1024)\n",
        "\n",
        "    initial_size = bytes_to_gb(os.path.getsize(model_path))\n",
        "\n",
        "    print(f\"\\n\u001b[1;32mPruning model ({prefix}): {model_path} ({initial_size:.2f} GB)\")\n",
        "    if is_safetensors(model_path):\n",
        "        input_sd = load_file(model_path)\n",
        "    else:\n",
        "        input_sd = load(model_path)  # type: ignore\n",
        "\n",
        "    pruned = prune_model(input_sd, fp16=(prefix == \"fp16\"))\n",
        "\n",
        "    model_name, ext = os.path.splitext(model_path)\n",
        "    output_path = f\"{model_name}-{prefix}{ext}\"\n",
        "\n",
        "    if is_safetensors(model_path):\n",
        "        save_file(pruned, output_path)\n",
        "    else:\n",
        "        save(pruned, output_path)\n",
        "\n",
        "    if \"/content/drive/MyDrive/\" not in model_path:\n",
        "        os.remove(model_path)\n",
        "\n",
        "    del input_sd, pruned\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    final_size = bytes_to_gb(os.path.getsize(output_path))\n",
        "    print(f\"\u001b[1;32mPruning completed: {output_path} ({final_size:.2f} GB)\")\n",
        "\n",
        "def get_most_recent_file(directory):\n",
        "    files = glob.glob(os.path.join(directory, \"*\"))\n",
        "    if not files:\n",
        "        return None\n",
        "    most_recent_file = max(files, key=os.path.getmtime)\n",
        "    return most_recent_file\n",
        "\n",
        "def get_filename(url):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        content_disposition = response.headers['content-disposition']\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
        "    else:\n",
        "        url_path = urlparse(url).path\n",
        "        filename = unquote(os.path.basename(url_path))\n",
        "        \n",
        "    return filename\n",
        "\n",
        "def download(url_list, dst_dir, is_extensions):\n",
        "    supported_extensions = [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]\n",
        "\n",
        "    desc = f\"\u001b[1;32mDownloading Custom {category.capitalize()}\"\n",
        "    if category == \"extensions\":\n",
        "        desc = f\"\u001b[1;32mInstalling Custom {category.capitalize()}\"\n",
        "\n",
        "    for url in tqdm(url_list, desc=desc):\n",
        "        if url:\n",
        "            url = url.strip()\n",
        "            prune_prefix = None\n",
        "            if url.startswith(\"fp32:\"):\n",
        "                prune_prefix = \"fp32\"\n",
        "                url = url[5:].strip()\n",
        "            elif url.startswith(\"fp16:\"):\n",
        "                prune_prefix = \"fp16\"\n",
        "                url = url[5:].strip()\n",
        "                \n",
        "            if url.startswith(\"fuse:\"):\n",
        "                folder_path = url[5:].strip()\n",
        "                unionfuse(folder_path, dst_dir)\n",
        "            else:\n",
        "                custom_download_list.append(url)\n",
        "                if url.startswith(\"/content/drive/MyDrive/\") or url.endswith(tuple(supported_extensions)):\n",
        "                    basename = os.path.basename(url)\n",
        "                else:\n",
        "                    basename = get_filename(url)\n",
        "\n",
        "                with capture.capture_output() as cap:\n",
        "                    if is_extensions:\n",
        "                        os.chdir(extensions_dir)\n",
        "                        if os.path.exists(basename):\n",
        "                            shutil.rmtree(os.path.join(extensions_dir, basename))\n",
        "                        !git clone {url}\n",
        "                    elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "                        Path(os.path.join(dst_dir, basename)).write_bytes(Path(url).read_bytes())\n",
        "                    elif \"drive.google.com\" in url:\n",
        "                        if \"folders\" in url:\n",
        "                            !gdown --folder \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                        else:\n",
        "                            !gdown \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                    elif \"huggingface.co\" in url:\n",
        "                        if \"/blob/\" in url:\n",
        "                            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "                        hf_token = \"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\"\n",
        "                        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    elif any(url.endswith(extension) for extension in supported_extensions):\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    else:\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} {url}\n",
        "\n",
        "                    extract(url, dst_dir)\n",
        "                del cap\n",
        "\n",
        "            if prune_prefix:\n",
        "                if \"model\" in category:\n",
        "                    try:\n",
        "                        if any(basename.endswith(extension) for extension in supported_extensions):\n",
        "                            model_path = os.path.join(dst_dir, basename)\n",
        "                            autoprune(model_path, prune_prefix)\n",
        "                        else:\n",
        "                            most_recent_file = get_most_recent_file(dst_dir)\n",
        "                            if most_recent_file is not None:\n",
        "                                autoprune(most_recent_file, prune_prefix)\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n\u001b[1;32mError pruning file: {e}\")\n",
        "                else:\n",
        "                    print(f\"\\n\u001b[1;32mOnly model can be pruned, skipping...\")\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for category, custom_url in [\n",
        "    (\"model\", custom_model_url),\n",
        "    (\"vae\", custom_vae_url),\n",
        "    (\"embedding\", custom_embedding_url),\n",
        "    (\"LoRA\", custom_LoRA_url),\n",
        "    (\"hypernetwork\", custom_hypernetwork_url),\n",
        "    (\"extensions\", custom_extensions_url),\n",
        "    (\"upscaler\", custom_upscaler_url),\n",
        "]:\n",
        "    if custom_url:\n",
        "        urls = custom_url.split(\",\")\n",
        "        download(urls, custom_dirs[category], category == \"extensions\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "print()\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")\n",
        "\n",
        "custom_download_list = []"
      ],
      "metadata": {
        "id": "PdjuRPcX0-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Cagliostro Colab UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#start-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "%store -r \n",
        "\n",
        "# @markdown ### **Alternative Tunnel**\n",
        "\n",
        "# @markdown > Recommended Tunnels: `ngrok` > `cloudflared` > `remotemoe` > `localhostrun` > `googleusercontent` > `gradio`\n",
        "tunnel = \"none\" # @param ['none', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token = \"\" # @param {type: 'string'}\n",
        "ngrok_region = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "# @markdown ### **UI Config**\n",
        "use_dark_theme = True # @param {type: 'boolean'}\n",
        "theme = \"default\" # @param ['tron2', 'ogxCyanInvert', 'ogxBGreen', 'ogxRed', 'default', 'moonlight', 'd-230-52-94', 'backup', 'tron', 'ogxRedYellow', 'default_orange', 'ogxRedPurple', 'retrog', 'ogxCyan', 'fun', 'ogxGreen', 'default_cyan', 'Golde']\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets = True # @param {type: 'boolean'}\n",
        "# @markdown ### **Arguments**\n",
        "use_gradio_auth = False # @param {type: 'boolean'}\n",
        "accelerator = \"xformers\" # @param ['xformers', 'opt-sdp-attention', 'opt-split-attention']\n",
        "auto_select_model = False # @param {type: 'boolean'}\n",
        "auto_select_VAE = True # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --no-half-vae --api\" #@param {type: 'string'}\n",
        "\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "ui_config_file = os.path.join(repo_dir, \"ui-config.json\")\n",
        "voldemort=base64.b64decode((\"'c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ=='\").encode('ascii')).decode('ascii')\n",
        "\n",
        "user = \"cagliostro\"\n",
        "password = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "            f.close()  \n",
        "\n",
        "def open_theme(filename):\n",
        "    themes_folder = os.path.join(repo_dir, \"extensions-builtin/sd_theme_editor/themes\")\n",
        "    themes_file = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "    webui_style_path = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "    style_config = read_config(webui_style_path)\n",
        "    style_css_contents = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config = read_config(themes_file)\n",
        "    style_data = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_css_contents\n",
        "    write_config(webui_style_path, style_data)\n",
        "\n",
        "def change_theme(filename):\n",
        "    try:\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote -v\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "\n",
        "    output = cap.stdout.strip()\n",
        "    if f\"https://github.com/anapnoe/{voldemort}-ux\" in output:\n",
        "        open_theme(filename)\n",
        "\n",
        "def is_dir_exist(cloned_dir, original_dir):\n",
        "    if os.path.exists(cloned_dir):\n",
        "        return cloned_dir \n",
        "    else:\n",
        "        return original_dir\n",
        "\n",
        "valid_ckpt_dir = is_dir_exist(os.path.join(fused_dir, \"model\"), models_dir)\n",
        "valid_vae_dir = is_dir_exist(os.path.join(fused_dir, \"vae\"), vaes_dir)\n",
        "valid_embedding_dir = is_dir_exist(os.path.join(fused_dir, \"embedding\"), embeddings_dir)\n",
        "valid_lora_dir = is_dir_exist(os.path.join(fused_dir, \"LoRA\"), lora_dir)\n",
        "valid_hypernetwork_dir = is_dir_exist(os.path.join(fused_dir, \"hypernetwork\"), hypernetworks_dir)\n",
        "\n",
        "if auto_select_model:\n",
        "    model_path = \"dummy.ckpt\"\n",
        "    models_list = os.listdir(valid_ckpt_dir)\n",
        "    model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "    if model_files:\n",
        "        model_path = random.choice(model_files)\n",
        "        if os.path.exists(os.path.join(valid_ckpt_dir, model_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_model_checkpoint\"] = model_path\n",
        "            write_config(config_file, config)\n",
        "\n",
        "if auto_select_VAE:\n",
        "    vae_path = \"dummy.pt\"\n",
        "    vaes_list = os.listdir(valid_vae_dir)\n",
        "    vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "    if vae_files:\n",
        "        vae_path = random.choice(vae_files)\n",
        "        if os.path.exists(os.path.join(valid_vae_dir, vae_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_vae\"] = vae_path\n",
        "            write_config(config_file, config) \n",
        "# config.json\n",
        "config = read_config(config_file)\n",
        "config[\"additional_networks_extra_lora_path\"] = valid_lora_dir\n",
        "config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "config[\"eta_noise_seed_delta\"] = 0\n",
        "config[\"show_progress_every_n_steps\"] = 10\n",
        "config[\"show_progressbar\"] = True\n",
        "config[\"quicksettings\"] = \"sd_model_checkpoint, sd_vae, CLIP_stop_at_last_layers, use_old_karras_scheduler_sigmas, always_discard_next_to_last_sigma\"\n",
        "write_config(config_file, config)\n",
        "\n",
        "if use_presets:\n",
        "    # ui-config.json\n",
        "    default_prompt = \"masterpiece, best quality,\"\n",
        "    default_neg_prompt = \"(worst quality, low quality:1.4)\"\n",
        "    default_sampler = \"DPM++ 2M Karras\"\n",
        "    if dpm_v2_patch:\n",
        "        default_sampler = \"DPM++ 2M Karras v2\" \n",
        "    default_steps = 20\n",
        "    default_width = 512\n",
        "    default_height = 768\n",
        "    default_denoising_strength = 0.55\n",
        "    default_cfg_scale = 7\n",
        "\n",
        "    # txt2img\n",
        "    config = read_config(ui_config_file)\n",
        "    config[\"txt2img/Prompt/value\"] = default_prompt\n",
        "    config[\"txt2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"txt2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"txt2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"txt2img/Width/value\"] = default_width\n",
        "    config[\"txt2img/Height/value\"] = default_height\n",
        "    config[\"txt2img/Upscaler/value\"] = \"Latent (nearest-exact)\"\n",
        "    config[\"txt2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"txt2img/CFG Scale/value\"] = default_cfg_scale\n",
        "\n",
        "    # img2img\n",
        "    config[\"img2img/Prompt/value\"] = default_prompt\n",
        "    config[\"img2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"img2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"img2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"img2img/Width/value\"] = default_width\n",
        "    config[\"img2img/Height/value\"] = default_height\n",
        "    config[\"img2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"img2img/CFG Scale/value\"] = default_cfg_scale\n",
        "    write_config(ui_config_file, config)\n",
        "              \n",
        "os.chdir(repo_dir)\n",
        "change_theme(theme)\n",
        "\n",
        "print(\"\u001b[1;32m\")\n",
        "\n",
        "if use_gradio_auth:\n",
        "      print(\"Gradio Auth (use this account to login):\")\n",
        "      print(\"- Username: cagliostro\")\n",
        "      print(\"- Password:\", password)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "config = {\n",
        "    \"enable-insecure-extension-access\": True,\n",
        "    \"disable-safe-unpickle\": True,\n",
        "    f\"{accelerator}\": True,\n",
        "    f\"{tunnel}\": True if not tunnel == \"none\" and not ngrok_token else False,\n",
        "    \"share\": True if not ngrok_token else False,\n",
        "    \"gradio-auth\": f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "    \"no-hashing\": True,\n",
        "    \"disable-console-progressbars\": True,\n",
        "    \"ngrok\": ngrok_token if ngrok_token else None,\n",
        "    \"ngrok-region\": ngrok_region if ngrok_token else None,\n",
        "    \"opt-sub-quad-attention\": True,\n",
        "    \"opt-channelslast\": True,\n",
        "    \"theme\": \"dark\" if use_dark_theme else \"light\",\n",
        "    \"no-download-sd-model\": True,\n",
        "    \"gradio-queue\": True,\n",
        "    \"listen\": True,\n",
        "    \"ckpt-dir\": valid_ckpt_dir,\n",
        "    \"vae-dir\": valid_vae_dir,\n",
        "    \"hypernetwork-dir\": valid_hypernetwork_dir,\n",
        "    \"embeddings-dir\": valid_embedding_dir,\n",
        "    \"lora-dir\": valid_lora_dir,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images)</small></small>\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "\n",
        "use_drive = False  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-colab-ui\"  # @param {type: \"string\"}\n",
        "filename = \"Illu3.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"Illu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"Illu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs2.zip .\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile(\n",
        "            {\n",
        "                \"q\": \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(\n",
        "                    folder_name\n",
        "                )\n",
        "            }\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: Folder exists\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            print(\"Debug: Creating folder\")\n",
        "            file = drive.CreateFile(\n",
        "                {\"title\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            )\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile(\n",
        "            {\"q\": \"title='{}' and trashed=false\".format(save_as)}\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: File already exists\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = (\n",
        "                    os.path.splitext(save_as)[0]\n",
        "                    + f\"({i})\"\n",
        "                    + os.path.splitext(save_as)[1]\n",
        "                )\n",
        "                file_list = drive.ListFile(\n",
        "                    {\"q\": \"title='{}' and trashed=false\".format(new_name)}\n",
        "                ).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    print(\n",
        "        \"Your sharing link: https://drive.google.com/file/d/\"\n",
        "        + file_id\n",
        "        + \"/view?usp=sharing\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "4SUHPtGLz2m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images V2** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images-v2)</small></small>\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# @markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"cagliostro-colab-ui\"  # @param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False  # @param{type:\"boolean\"}\n",
        "# @markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\"  # @param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"waifu\"\n",
        "\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \" + dataset_zip + \" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "    print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "    try:\n",
        "        validate_repo_id(datasets_repo)\n",
        "        api.create_repo(\n",
        "            repo_id=datasets_repo, repo_type=\"dataset\", private=private_repo\n",
        "        )\n",
        "        print(\n",
        "            f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\"\n",
        "        )\n",
        "\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "    !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=output_path,\n",
        "    path_in_repo=dataset_zip,\n",
        "    repo_id=datasets_repo,\n",
        "    repo_type=\"dataset\",\n",
        "    commit_message=commit_message,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\"\n",
        ")\n",
        "\n",
        "os.remove(output_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EGXqJLXwnJQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
